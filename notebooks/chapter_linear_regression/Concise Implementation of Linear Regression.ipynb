{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce38799-3629-4a75-89ee-bdfb95a6bff3",
   "metadata": {},
   "source": [
    "# Concise Implementation of Linear Regression\n",
    "\n",
    "Deep learning has witnessed a Cambrian explosion of sorts over the past decade. The sheer number of techniques, applications and algorithms by far surpasses the progress of previous decades. This is due to a fortuitous combination of multiple factors, one of which is the powerful free tools offered by a number of open source deep learning frameworks. Theano (Bergstra et al., 2010), DistBelief (Dean et al., 2012), and Caffe (Jia et al., 2014) arguably represent the first generation of such models that found widespread adoption. In contrast to earlier (seminal) works like SN2 (Simulateur Neuristique) (Bottou and Le Cun, 1988), which provided a Lisp-like programming experience, modern frameworks offer automatic differentiation and the convenience of Julia. These frameworks allow us to automate and modularize the repetitive work of implementing gradient-based learning algorithms.\n",
    "\n",
    "In Section 3.4, we relied only on (i) tensors for data storage and linear algebra; and (ii) automatic differentiation for calculating gradients. In practice, because data iterators, loss functions, optimizers, and neural network layers are so common, modern libraries implement these components for us as well. In this section, we will show you how to implement the linear regression model from Section 3.4 concisely by using high-level APIs of deep learning frameworks.\n",
    "\n",
    "## Generating the Dataset\n",
    "\n",
    "For this example, we will work low-dimensional for succinctness. The following code snippet generates 1000 examples with 2-dimensional features drawn from a standard normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fefdba1-1393-46ff-8b98-0eb2f5530135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "synthetic_data (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "function synthetic_data(w::Vector{<:Real},b::Real,num_example::Int)\n",
    "    X = rand(Normal(0,1),(num_example,length(w)))\n",
    "    y = X * w .+ b\n",
    "    y += rand(Normal(0,0.01),(size(y)))\n",
    "    return X',y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38300e62-50d1-4566-aaf5-d589b79c4482",
   "metadata": {},
   "source": [
    "Later, we can check our estimated parameters against these ground truth values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b60d498-4f00-429d-89f0-52738ac6aaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.14619589632160165 1.3906239203897983 … -0.19059142703720552 0.14345235980909807; 1.9135127909065464 0.2650503275663784 … 0.8634588460090279 0.3644827666846965], [-2.012942409291826, 6.084187903685514, 1.814663421623127, 12.026125408555579, 2.2966439611326224, -1.7288451861623593, 6.0209413829411815, 0.3864627570256396, 7.1530735946813016, 3.1171856744911026  …  5.458526207305779, 1.1371184528082483, 6.59211298956371, 10.489637581895897, 3.811671968815091, 3.194875126840119, 6.25205350737315, 11.77415713545804, 0.8749169028874869, 3.243621500894337])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features,labels = synthetic_data([2, -3.4],4.2,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ed7e7-6ae7-4d0d-a7cb-057ccec325e0",
   "metadata": {},
   "source": [
    "Let’s have a look at the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfe522c-14db-4fc7-b018-583d00544fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:[0.14619589632160165, 1.9135127909065464]\n",
      "label:-2.012942409291826\n"
     ]
    }
   ],
   "source": [
    "println(\"features:$(features[:,1])\")\n",
    "println(\"label:$(labels[1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d11fe8-aec2-4efb-b787-f07f72e6bd26",
   "metadata": {},
   "source": [
    "## Reading the Dataset\n",
    "\n",
    "To build some intuition, let’s inspect the first minibatch of data. Each minibatch of features provides us with both its size and the dimensionality of input features. Likewise, our minibatch of labels will have a matching shape given by `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41a01ae-f245-463b-997f-c4dd1558df0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(2, 10)\n",
      "y shape:(10,)\n"
     ]
    }
   ],
   "source": [
    "using MLUtils\n",
    "train_loader = DataLoader((features,labels),batchsize=10,shuffle=true)\n",
    "X,y = first(train_loader)\n",
    "println(\"X shape:$(size(X))\")\n",
    "println(\"y shape:$(size(y))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f93d6f-b4bf-42cf-a267-42ad0d81943d",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "For standard operations, we can use a framework’s predefined layers, which allow us to focus on the layers used to construct the model rather than worrying about their implementation. Recall the architecture of a single-layer network as described in Fig. 3.1.2. The layer is called fully connected, since each of its inputs is connected to each of its outputs by means of a matrix-vector multiplication.\n",
    "\n",
    "A `Dense(2 => 1)` layer denotes a layer of one neuron with one input (one feature) and one output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed97383-1758-4de5-842e-d35e9c729bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(2 => 1)       \u001b[90m# 3 parameters\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "model = Dense(2=>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2405c1-b338-487a-9f1c-9c6621207762",
   "metadata": {},
   "source": [
    "## Defining the Loss Function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
